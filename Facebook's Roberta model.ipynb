{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook's Roberta model.\n",
    "\n",
    "The Code below tests Roberta on sentences it has not seen before to check if it believes the sentences are contradicting each other, are neutral or are in contextual agreement or entailment. The model was fine-tuned for the MNLI dataset set. I was curious to see how it did on a small sample of sentences it had not seen before\n",
    "\n",
    "To be clear the model has three possible answers. The sentence pairs are classed by ROBERTA as one of the following possibilities.\n",
    "\n",
    "1. They contradict each other.\n",
    "2. They are neutral with respect to each other.\n",
    "3. They are in agreement and follow on logically from the first to the second sentence,(Entailment).\n",
    "\n",
    "Results below\n",
    "\n",
    "##### Aug 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/brianfarrell/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.mnli.tar.gz from cache at /Users/brianfarrell/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8\n",
      "| dictionary: 50264 types\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile \n",
    "#Get model from Facebook torch hub\n",
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_roberta():     \n",
    "    #Three sentence pairs to test the model on.\n",
    "    s1=[('Jamie is CEO of a bank as of August 2019.'),('The client asked me to do it.'),('The client wanted me to buy it on the open and call her stright away.')] \n",
    "    s2=[('Jamie was fired from the bank in July 2019.'),('I didnt get permission from the client.'),('Once I bought it for the client I called the client immediately.')] \n",
    "    for i in range(3): \n",
    "        label= {0:'Contradiction',1:'Neutral',2:'Entailment'}\n",
    "        pred=[]\n",
    "        tokens = roberta.encode(s1[i], s2[i])\n",
    "        prediction = roberta.predict('mnli', tokens).argmax().item()     \n",
    "        for k,v in label.items():\n",
    "            if prediction == k:\n",
    "                pred.append(v)\n",
    "                print(\"\")            \n",
    "                print(s1[i],s2[i],\"\",\"Roberta's prediction:\",pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jamie is CEO of a bank as of August 2019. Jamie was fired from the bank in July 2019.  Roberta's prediction: ['Contradiction']\n",
      "\n",
      "The client asked me to do it. I didnt get permission from the client.  Roberta's prediction: ['Contradiction']\n",
      "\n",
      "The client wanted me to buy it on the open and call her stright away. Once I bought it for the client I called the client immediately.  Roberta's prediction: ['Entailment']\n"
     ]
    }
   ],
   "source": [
    "#Call the model \n",
    "hello_roberta()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
