 
Testing Facebook & Washington University's new ROBERTA model. 

ROBERTA is a twist on Google's BERT model.

In essence both machine learning models are the best-in-class at reading and understanding language. From that basis they can be fine-tuned to carry out multiple tasks including classifying emails, social media content or any content input to browsers, etc.

In the accompanying file of this repo is a quick test of a ROBERTA pre-trained(MNLI) model.  

As background I use neural network models like these to help analyse and classify electronic communications within the financial services industry domain. 
  
link to research paper on Roberta:
https://arxiv.org/pdf/1907.11692.pdf
